{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "8RM6raocvnlv"
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import tensorflow\n",
    "np.random.seed(2)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold, KFold\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization, Input\n",
    "\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, ModelCheckpoint\n",
    "import tensorflow_addons as tfa\n",
    "from sklearn.metrics import log_loss\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "AoLBd5Gj4u7f"
   },
   "outputs": [],
   "source": [
    "data_train = pd.read_csv('train_features.csv')\n",
    "data_test = pd.read_csv('test_features.csv')\n",
    "data_train_target_ns = pd.read_csv('train_targets_nonscored.csv')\n",
    "data_train_target_s = pd.read_csv('train_targets_scored.csv')\n",
    "sub = pd.read_csv('sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 270
    },
    "id": "wVuX09je4yaO",
    "outputId": "a9405a20-8e78-4cbe-d80f-3c5444c412b8"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sig_id</th>\n",
       "      <th>cp_type</th>\n",
       "      <th>cp_time</th>\n",
       "      <th>cp_dose</th>\n",
       "      <th>g-0</th>\n",
       "      <th>g-1</th>\n",
       "      <th>g-2</th>\n",
       "      <th>g-3</th>\n",
       "      <th>g-4</th>\n",
       "      <th>g-5</th>\n",
       "      <th>...</th>\n",
       "      <th>c-90</th>\n",
       "      <th>c-91</th>\n",
       "      <th>c-92</th>\n",
       "      <th>c-93</th>\n",
       "      <th>c-94</th>\n",
       "      <th>c-95</th>\n",
       "      <th>c-96</th>\n",
       "      <th>c-97</th>\n",
       "      <th>c-98</th>\n",
       "      <th>c-99</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>id_000644bb2</td>\n",
       "      <td>trt_cp</td>\n",
       "      <td>24</td>\n",
       "      <td>D1</td>\n",
       "      <td>1.0620</td>\n",
       "      <td>0.5577</td>\n",
       "      <td>-0.2479</td>\n",
       "      <td>-0.6208</td>\n",
       "      <td>-0.1944</td>\n",
       "      <td>-1.0120</td>\n",
       "      <td>...</td>\n",
       "      <td>0.2862</td>\n",
       "      <td>0.2584</td>\n",
       "      <td>0.8076</td>\n",
       "      <td>0.5523</td>\n",
       "      <td>-0.1912</td>\n",
       "      <td>0.6584</td>\n",
       "      <td>-0.3981</td>\n",
       "      <td>0.2139</td>\n",
       "      <td>0.3801</td>\n",
       "      <td>0.4176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>id_000779bfc</td>\n",
       "      <td>trt_cp</td>\n",
       "      <td>72</td>\n",
       "      <td>D1</td>\n",
       "      <td>0.0743</td>\n",
       "      <td>0.4087</td>\n",
       "      <td>0.2991</td>\n",
       "      <td>0.0604</td>\n",
       "      <td>1.0190</td>\n",
       "      <td>0.5207</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.4265</td>\n",
       "      <td>0.7543</td>\n",
       "      <td>0.4708</td>\n",
       "      <td>0.0230</td>\n",
       "      <td>0.2957</td>\n",
       "      <td>0.4899</td>\n",
       "      <td>0.1522</td>\n",
       "      <td>0.1241</td>\n",
       "      <td>0.6077</td>\n",
       "      <td>0.7371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>id_000a6266a</td>\n",
       "      <td>trt_cp</td>\n",
       "      <td>48</td>\n",
       "      <td>D1</td>\n",
       "      <td>0.6280</td>\n",
       "      <td>0.5817</td>\n",
       "      <td>1.5540</td>\n",
       "      <td>-0.0764</td>\n",
       "      <td>-0.0323</td>\n",
       "      <td>1.2390</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.7250</td>\n",
       "      <td>-0.6297</td>\n",
       "      <td>0.6103</td>\n",
       "      <td>0.0223</td>\n",
       "      <td>-1.3240</td>\n",
       "      <td>-0.3174</td>\n",
       "      <td>-0.6417</td>\n",
       "      <td>-0.2187</td>\n",
       "      <td>-1.4080</td>\n",
       "      <td>0.6931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>id_0015fd391</td>\n",
       "      <td>trt_cp</td>\n",
       "      <td>48</td>\n",
       "      <td>D1</td>\n",
       "      <td>-0.5138</td>\n",
       "      <td>-0.2491</td>\n",
       "      <td>-0.2656</td>\n",
       "      <td>0.5288</td>\n",
       "      <td>4.0620</td>\n",
       "      <td>-0.8095</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.0990</td>\n",
       "      <td>-0.6441</td>\n",
       "      <td>-5.6300</td>\n",
       "      <td>-1.3780</td>\n",
       "      <td>-0.8632</td>\n",
       "      <td>-1.2880</td>\n",
       "      <td>-1.6210</td>\n",
       "      <td>-0.8784</td>\n",
       "      <td>-0.3876</td>\n",
       "      <td>-0.8154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>id_001626bd3</td>\n",
       "      <td>trt_cp</td>\n",
       "      <td>72</td>\n",
       "      <td>D2</td>\n",
       "      <td>-0.3254</td>\n",
       "      <td>-0.4009</td>\n",
       "      <td>0.9700</td>\n",
       "      <td>0.6919</td>\n",
       "      <td>1.4180</td>\n",
       "      <td>-0.8244</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0042</td>\n",
       "      <td>0.0048</td>\n",
       "      <td>0.6670</td>\n",
       "      <td>1.0690</td>\n",
       "      <td>0.5523</td>\n",
       "      <td>-0.3031</td>\n",
       "      <td>0.1094</td>\n",
       "      <td>0.2885</td>\n",
       "      <td>-0.3786</td>\n",
       "      <td>0.7125</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 876 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         sig_id cp_type  cp_time cp_dose     g-0     g-1     g-2     g-3  \\\n",
       "0  id_000644bb2  trt_cp       24      D1  1.0620  0.5577 -0.2479 -0.6208   \n",
       "1  id_000779bfc  trt_cp       72      D1  0.0743  0.4087  0.2991  0.0604   \n",
       "2  id_000a6266a  trt_cp       48      D1  0.6280  0.5817  1.5540 -0.0764   \n",
       "3  id_0015fd391  trt_cp       48      D1 -0.5138 -0.2491 -0.2656  0.5288   \n",
       "4  id_001626bd3  trt_cp       72      D2 -0.3254 -0.4009  0.9700  0.6919   \n",
       "\n",
       "      g-4     g-5  ...    c-90    c-91    c-92    c-93    c-94    c-95  \\\n",
       "0 -0.1944 -1.0120  ...  0.2862  0.2584  0.8076  0.5523 -0.1912  0.6584   \n",
       "1  1.0190  0.5207  ... -0.4265  0.7543  0.4708  0.0230  0.2957  0.4899   \n",
       "2 -0.0323  1.2390  ... -0.7250 -0.6297  0.6103  0.0223 -1.3240 -0.3174   \n",
       "3  4.0620 -0.8095  ... -2.0990 -0.6441 -5.6300 -1.3780 -0.8632 -1.2880   \n",
       "4  1.4180 -0.8244  ...  0.0042  0.0048  0.6670  1.0690  0.5523 -0.3031   \n",
       "\n",
       "     c-96    c-97    c-98    c-99  \n",
       "0 -0.3981  0.2139  0.3801  0.4176  \n",
       "1  0.1522  0.1241  0.6077  0.7371  \n",
       "2 -0.6417 -0.2187 -1.4080  0.6931  \n",
       "3 -1.6210 -0.8784 -0.3876 -0.8154  \n",
       "4  0.1094  0.2885 -0.3786  0.7125  \n",
       "\n",
       "[5 rows x 876 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SHAPE of training data-- (23814, 876)\n"
     ]
    }
   ],
   "source": [
    "display(data_train.head())\n",
    "print(\"SHAPE of training data--\",data_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 270
    },
    "id": "573MGViH5Zix",
    "outputId": "70a1b1d2-d076-421c-9977-48af9b96b6a8"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sig_id</th>\n",
       "      <th>cp_type</th>\n",
       "      <th>cp_time</th>\n",
       "      <th>cp_dose</th>\n",
       "      <th>g-0</th>\n",
       "      <th>g-1</th>\n",
       "      <th>g-2</th>\n",
       "      <th>g-3</th>\n",
       "      <th>g-4</th>\n",
       "      <th>g-5</th>\n",
       "      <th>...</th>\n",
       "      <th>c-90</th>\n",
       "      <th>c-91</th>\n",
       "      <th>c-92</th>\n",
       "      <th>c-93</th>\n",
       "      <th>c-94</th>\n",
       "      <th>c-95</th>\n",
       "      <th>c-96</th>\n",
       "      <th>c-97</th>\n",
       "      <th>c-98</th>\n",
       "      <th>c-99</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>id_0004d9e33</td>\n",
       "      <td>trt_cp</td>\n",
       "      <td>24</td>\n",
       "      <td>D1</td>\n",
       "      <td>-0.5458</td>\n",
       "      <td>0.1306</td>\n",
       "      <td>-0.5135</td>\n",
       "      <td>0.4408</td>\n",
       "      <td>1.5500</td>\n",
       "      <td>-0.1644</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0981</td>\n",
       "      <td>0.7978</td>\n",
       "      <td>-0.1430</td>\n",
       "      <td>-0.2067</td>\n",
       "      <td>-0.2303</td>\n",
       "      <td>-0.1193</td>\n",
       "      <td>0.0210</td>\n",
       "      <td>-0.0502</td>\n",
       "      <td>0.1510</td>\n",
       "      <td>-0.7750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>id_001897cda</td>\n",
       "      <td>trt_cp</td>\n",
       "      <td>72</td>\n",
       "      <td>D1</td>\n",
       "      <td>-0.1829</td>\n",
       "      <td>0.2320</td>\n",
       "      <td>1.2080</td>\n",
       "      <td>-0.4522</td>\n",
       "      <td>-0.3652</td>\n",
       "      <td>-0.3319</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.1190</td>\n",
       "      <td>-0.1852</td>\n",
       "      <td>-1.0310</td>\n",
       "      <td>-1.3670</td>\n",
       "      <td>-0.3690</td>\n",
       "      <td>-0.5382</td>\n",
       "      <td>0.0359</td>\n",
       "      <td>-0.4764</td>\n",
       "      <td>-1.3810</td>\n",
       "      <td>-0.7300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>id_002429b5b</td>\n",
       "      <td>ctl_vehicle</td>\n",
       "      <td>24</td>\n",
       "      <td>D1</td>\n",
       "      <td>0.1852</td>\n",
       "      <td>-0.1404</td>\n",
       "      <td>-0.3911</td>\n",
       "      <td>0.1310</td>\n",
       "      <td>-1.4380</td>\n",
       "      <td>0.2455</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.2261</td>\n",
       "      <td>0.3370</td>\n",
       "      <td>-1.3840</td>\n",
       "      <td>0.8604</td>\n",
       "      <td>-1.9530</td>\n",
       "      <td>-1.0140</td>\n",
       "      <td>0.8662</td>\n",
       "      <td>1.0160</td>\n",
       "      <td>0.4924</td>\n",
       "      <td>-0.1942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>id_00276f245</td>\n",
       "      <td>trt_cp</td>\n",
       "      <td>24</td>\n",
       "      <td>D2</td>\n",
       "      <td>0.4828</td>\n",
       "      <td>0.1955</td>\n",
       "      <td>0.3825</td>\n",
       "      <td>0.4244</td>\n",
       "      <td>-0.5855</td>\n",
       "      <td>-1.2020</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1260</td>\n",
       "      <td>0.1570</td>\n",
       "      <td>-0.1784</td>\n",
       "      <td>-1.1200</td>\n",
       "      <td>-0.4325</td>\n",
       "      <td>-0.9005</td>\n",
       "      <td>0.8131</td>\n",
       "      <td>-0.1305</td>\n",
       "      <td>0.5645</td>\n",
       "      <td>-0.5809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>id_0027f1083</td>\n",
       "      <td>trt_cp</td>\n",
       "      <td>48</td>\n",
       "      <td>D1</td>\n",
       "      <td>-0.3979</td>\n",
       "      <td>-1.2680</td>\n",
       "      <td>1.9130</td>\n",
       "      <td>0.2057</td>\n",
       "      <td>-0.5864</td>\n",
       "      <td>-0.0166</td>\n",
       "      <td>...</td>\n",
       "      <td>0.4965</td>\n",
       "      <td>0.7578</td>\n",
       "      <td>-0.1580</td>\n",
       "      <td>1.0510</td>\n",
       "      <td>0.5742</td>\n",
       "      <td>1.0900</td>\n",
       "      <td>-0.2962</td>\n",
       "      <td>-0.5313</td>\n",
       "      <td>0.9931</td>\n",
       "      <td>1.8380</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 876 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         sig_id      cp_type  cp_time cp_dose     g-0     g-1     g-2     g-3  \\\n",
       "0  id_0004d9e33       trt_cp       24      D1 -0.5458  0.1306 -0.5135  0.4408   \n",
       "1  id_001897cda       trt_cp       72      D1 -0.1829  0.2320  1.2080 -0.4522   \n",
       "2  id_002429b5b  ctl_vehicle       24      D1  0.1852 -0.1404 -0.3911  0.1310   \n",
       "3  id_00276f245       trt_cp       24      D2  0.4828  0.1955  0.3825  0.4244   \n",
       "4  id_0027f1083       trt_cp       48      D1 -0.3979 -1.2680  1.9130  0.2057   \n",
       "\n",
       "      g-4     g-5  ...    c-90    c-91    c-92    c-93    c-94    c-95  \\\n",
       "0  1.5500 -0.1644  ...  0.0981  0.7978 -0.1430 -0.2067 -0.2303 -0.1193   \n",
       "1 -0.3652 -0.3319  ... -0.1190 -0.1852 -1.0310 -1.3670 -0.3690 -0.5382   \n",
       "2 -1.4380  0.2455  ... -0.2261  0.3370 -1.3840  0.8604 -1.9530 -1.0140   \n",
       "3 -0.5855 -1.2020  ...  0.1260  0.1570 -0.1784 -1.1200 -0.4325 -0.9005   \n",
       "4 -0.5864 -0.0166  ...  0.4965  0.7578 -0.1580  1.0510  0.5742  1.0900   \n",
       "\n",
       "     c-96    c-97    c-98    c-99  \n",
       "0  0.0210 -0.0502  0.1510 -0.7750  \n",
       "1  0.0359 -0.4764 -1.3810 -0.7300  \n",
       "2  0.8662  1.0160  0.4924 -0.1942  \n",
       "3  0.8131 -0.1305  0.5645 -0.5809  \n",
       "4 -0.2962 -0.5313  0.9931  1.8380  \n",
       "\n",
       "[5 rows x 876 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SHAPE of test data-- (3982, 876)\n"
     ]
    }
   ],
   "source": [
    "display(data_test.head())\n",
    "print(\"SHAPE of test data--\",data_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "KvBevkbx5aL7"
   },
   "outputs": [],
   "source": [
    "def preprocess(df):\n",
    "    df.loc[:, 'cp_type'] = df.loc[:, 'cp_type'].map({'trt_cp': 0, 'ctl_vehicle': 1})\n",
    "    df.loc[:, 'cp_dose'] = df.loc[:, 'cp_dose'].map({'D1': 0, 'D2': 1})\n",
    "    df.loc[:, 'cp_time'] = df.loc[:, 'cp_time'].map({24: 0, 48: 1, 72:2})\n",
    "    del df['sig_id']\n",
    "    return df\n",
    "\n",
    "train = preprocess(data_train)\n",
    "test = preprocess(data_test)\n",
    "\n",
    "del data_train_target_s['sig_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "GqViXeXt5dqY"
   },
   "outputs": [],
   "source": [
    "def create_model(num_columns):\n",
    "    model = Sequential()\n",
    "    model.add(Input(num_columns))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dense(2048, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    \n",
    "    model.add(Dense(1024, activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.5))\n",
    "    \n",
    "    model.add(Dense(206, activation='sigmoid'))\n",
    "    \n",
    "    optimizer = tfa.optimizers.Lookahead('adam',sync_period=10)\n",
    "    \n",
    "    model.compile(optimizer=optimizer,\n",
    "                  loss='binary_crossentropy', \n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "_tkntNZz5h6Z"
   },
   "outputs": [],
   "source": [
    "def metric(y_true, y_pred):\n",
    "    metrics = []\n",
    "    for _target in data_train_target_s.columns:\n",
    "        metrics.append(log_loss(y_true.loc[:, _target], y_pred.loc[:, _target].astype(float), labels=[0,1]))\n",
    "    return np.mean(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ifwUz-zs5jfs",
    "outputId": "2f4491dc-b943-48a7-bef0-c49485872696"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "batch_normalization_2 (Batch (None, 875)               3500      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 2048)              1794048   \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1024)              2098176   \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 1024)              4096      \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 206)               211150    \n",
      "=================================================================\n",
      "Total params: 4,110,970\n",
      "Trainable params: 4,107,172\n",
      "Non-trainable params: 3,798\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:`epsilon` argument is deprecated and will be removed, use `min_delta` instead.\n",
      "Epoch 1/25\n",
      "149/149 [==============================] - 20s 134ms/step - loss: 0.5913 - accuracy: 0.0131 - val_loss: 0.1727 - val_accuracy: 0.0661 - lr: 0.0010\n",
      "Epoch 2/25\n",
      "149/149 [==============================] - 22s 151ms/step - loss: 0.0940 - accuracy: 0.0282 - val_loss: 0.0351 - val_accuracy: 0.0485 - lr: 0.0010\n",
      "Epoch 3/25\n",
      "149/149 [==============================] - 23s 153ms/step - loss: 0.0321 - accuracy: 0.0482 - val_loss: 0.0237 - val_accuracy: 0.0556 - lr: 0.0010\n",
      "Epoch 4/25\n",
      "149/149 [==============================] - 23s 156ms/step - loss: 0.0240 - accuracy: 0.0608 - val_loss: 0.0209 - val_accuracy: 0.0886 - lr: 0.0010\n",
      "Epoch 5/25\n",
      "149/149 [==============================] - 27s 179ms/step - loss: 0.0218 - accuracy: 0.0650 - val_loss: 0.0198 - val_accuracy: 0.0911 - lr: 0.0010\n",
      "Epoch 6/25\n",
      "149/149 [==============================] - 30s 204ms/step - loss: 0.0207 - accuracy: 0.0692 - val_loss: 0.0191 - val_accuracy: 0.1052 - lr: 0.0010\n",
      "Epoch 7/25\n",
      "149/149 [==============================] - 29s 193ms/step - loss: 0.0197 - accuracy: 0.0797 - val_loss: 0.0185 - val_accuracy: 0.0848 - lr: 0.0010\n",
      "Epoch 8/25\n",
      "149/149 [==============================] - 25s 171ms/step - loss: 0.0194 - accuracy: 0.0862 - val_loss: 0.0180 - val_accuracy: 0.0884 - lr: 0.0010\n",
      "Epoch 9/25\n",
      "149/149 [==============================] - 27s 179ms/step - loss: 0.0189 - accuracy: 0.0935 - val_loss: 0.0177 - val_accuracy: 0.0909 - lr: 0.0010\n",
      "Epoch 10/25\n",
      "149/149 [==============================] - 26s 176ms/step - loss: 0.0186 - accuracy: 0.0983 - val_loss: 0.0176 - val_accuracy: 0.0957 - lr: 0.0010\n",
      "Epoch 11/25\n",
      "149/149 [==============================] - 27s 184ms/step - loss: 0.0182 - accuracy: 0.1011 - val_loss: 0.0172 - val_accuracy: 0.0993 - lr: 0.0010\n",
      "Epoch 12/25\n",
      "149/149 [==============================] - 28s 188ms/step - loss: 0.0177 - accuracy: 0.1079 - val_loss: 0.0172 - val_accuracy: 0.1302 - lr: 0.0010\n",
      "Epoch 13/25\n",
      "149/149 [==============================] - 28s 191ms/step - loss: 0.0172 - accuracy: 0.1109 - val_loss: 0.0167 - val_accuracy: 0.1211 - lr: 0.0010\n",
      "Epoch 14/25\n",
      "149/149 [==============================] - 27s 178ms/step - loss: 0.0169 - accuracy: 0.1157 - val_loss: 0.0165 - val_accuracy: 0.1054 - lr: 0.0010\n",
      "Epoch 15/25\n",
      "149/149 [==============================] - 23s 156ms/step - loss: 0.0168 - accuracy: 0.1195 - val_loss: 0.0167 - val_accuracy: 0.1132 - lr: 0.0010\n",
      "Epoch 16/25\n",
      "149/149 [==============================] - 28s 189ms/step - loss: 0.0164 - accuracy: 0.1227 - val_loss: 0.0161 - val_accuracy: 0.1155 - lr: 0.0010\n",
      "Epoch 17/25\n",
      "149/149 [==============================] - 29s 191ms/step - loss: 0.0159 - accuracy: 0.1288 - val_loss: 0.0160 - val_accuracy: 0.1165 - lr: 0.0010\n",
      "Epoch 18/25\n",
      "149/149 [==============================] - 31s 211ms/step - loss: 0.0162 - accuracy: 0.1323 - val_loss: 0.0171 - val_accuracy: 0.1067 - lr: 0.0010\n",
      "Epoch 19/25\n",
      "149/149 [==============================] - 27s 183ms/step - loss: 0.0164 - accuracy: 0.1329 - val_loss: 0.0163 - val_accuracy: 0.1155 - lr: 0.0010\n",
      "Epoch 20/25\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.0157 - accuracy: 0.1394\n",
      "Epoch 00020: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "149/149 [==============================] - 33s 221ms/step - loss: 0.0157 - accuracy: 0.1394 - val_loss: 0.0160 - val_accuracy: 0.1184 - lr: 0.0010\n",
      "Epoch 21/25\n",
      "149/149 [==============================] - 35s 235ms/step - loss: 0.0151 - accuracy: 0.1470 - val_loss: 0.0158 - val_accuracy: 0.1214 - lr: 1.0000e-04\n",
      "Epoch 22/25\n",
      "149/149 [==============================] - 32s 213ms/step - loss: 0.0149 - accuracy: 0.1492 - val_loss: 0.0157 - val_accuracy: 0.1241 - lr: 1.0000e-04\n",
      "Epoch 23/25\n",
      "149/149 [==============================] - 27s 184ms/step - loss: 0.0149 - accuracy: 0.1531 - val_loss: 0.0157 - val_accuracy: 0.1266 - lr: 1.0000e-04\n",
      "Epoch 24/25\n",
      "149/149 [==============================] - 23s 157ms/step - loss: 0.0147 - accuracy: 0.1552 - val_loss: 0.0156 - val_accuracy: 0.1253 - lr: 1.0000e-04\n",
      "Epoch 25/25\n",
      "149/149 [==============================] - 23s 154ms/step - loss: 0.0146 - accuracy: 0.1548 - val_loss: 0.0156 - val_accuracy: 0.1245 - lr: 1.0000e-04\n",
      "\n",
      "Fold 1\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "batch_normalization_4 (Batch (None, 875)               3500      \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 2048)              1794048   \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 1024)              2098176   \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 1024)              4096      \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 206)               211150    \n",
      "=================================================================\n",
      "Total params: 4,110,970\n",
      "Trainable params: 4,107,172\n",
      "Non-trainable params: 3,798\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:`epsilon` argument is deprecated and will be removed, use `min_delta` instead.\n",
      "Epoch 1/25\n",
      "149/149 [==============================] - 26s 176ms/step - loss: 0.5907 - accuracy: 0.0168 - val_loss: 0.1727 - val_accuracy: 0.0294 - lr: 0.0010\n",
      "Epoch 2/25\n",
      "149/149 [==============================] - 23s 155ms/step - loss: 0.0934 - accuracy: 0.0262 - val_loss: 0.0349 - val_accuracy: 0.0582 - lr: 0.0010\n",
      "Epoch 3/25\n",
      "149/149 [==============================] - 25s 165ms/step - loss: 0.0325 - accuracy: 0.0430 - val_loss: 0.0239 - val_accuracy: 0.0567 - lr: 0.0010\n",
      "Epoch 4/25\n",
      "149/149 [==============================] - 24s 161ms/step - loss: 0.0244 - accuracy: 0.0573 - val_loss: 0.0207 - val_accuracy: 0.0869 - lr: 0.0010\n",
      "Epoch 5/25\n",
      "149/149 [==============================] - 39s 265ms/step - loss: 0.0219 - accuracy: 0.0659 - val_loss: 0.0196 - val_accuracy: 0.0959 - lr: 0.0010\n",
      "Epoch 6/25\n",
      "149/149 [==============================] - 28s 186ms/step - loss: 0.0212 - accuracy: 0.0742 - val_loss: 0.0194 - val_accuracy: 0.0815 - lr: 0.0010\n",
      "Epoch 7/25\n",
      "149/149 [==============================] - 26s 174ms/step - loss: 0.0200 - accuracy: 0.0812 - val_loss: 0.0186 - val_accuracy: 0.1043 - lr: 0.0010\n",
      "Epoch 8/25\n",
      "149/149 [==============================] - 21s 143ms/step - loss: 0.0195 - accuracy: 0.0886 - val_loss: 0.0183 - val_accuracy: 0.1094 - lr: 0.0010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/25\n",
      "149/149 [==============================] - 26s 174ms/step - loss: 0.0186 - accuracy: 0.0938 - val_loss: 0.0177 - val_accuracy: 0.1136 - lr: 0.0010\n",
      "Epoch 10/25\n",
      "149/149 [==============================] - 30s 201ms/step - loss: 0.0183 - accuracy: 0.1011 - val_loss: 0.0176 - val_accuracy: 0.0991 - lr: 0.0010\n",
      "Epoch 11/25\n",
      "149/149 [==============================] - 23s 153ms/step - loss: 0.0180 - accuracy: 0.1059 - val_loss: 0.0173 - val_accuracy: 0.1136 - lr: 0.0010\n",
      "Epoch 12/25\n",
      "149/149 [==============================] - 30s 199ms/step - loss: 0.0174 - accuracy: 0.1125 - val_loss: 0.0169 - val_accuracy: 0.1260 - lr: 0.0010\n",
      "Epoch 13/25\n",
      "149/149 [==============================] - 28s 190ms/step - loss: 0.0172 - accuracy: 0.1170 - val_loss: 0.0169 - val_accuracy: 0.1247 - lr: 0.0010\n",
      "Epoch 14/25\n",
      "149/149 [==============================] - 25s 170ms/step - loss: 0.0169 - accuracy: 0.1183 - val_loss: 0.0167 - val_accuracy: 0.1054 - lr: 0.0010\n",
      "Epoch 15/25\n",
      "149/149 [==============================] - 22s 147ms/step - loss: 0.0165 - accuracy: 0.1266 - val_loss: 0.0163 - val_accuracy: 0.1064 - lr: 0.0010\n",
      "Epoch 16/25\n",
      "149/149 [==============================] - 29s 193ms/step - loss: 0.0164 - accuracy: 0.1312 - val_loss: 0.0163 - val_accuracy: 0.1098 - lr: 0.0010\n",
      "Epoch 17/25\n",
      "149/149 [==============================] - 21s 143ms/step - loss: 0.0166 - accuracy: 0.1289 - val_loss: 0.0163 - val_accuracy: 0.1115 - lr: 0.0010\n",
      "Epoch 18/25\n",
      "149/149 [==============================] - 28s 189ms/step - loss: 0.0160 - accuracy: 0.1388 - val_loss: 0.0161 - val_accuracy: 0.1106 - lr: 0.0010\n",
      "Epoch 19/25\n",
      "149/149 [==============================] - 25s 170ms/step - loss: 0.0156 - accuracy: 0.1442 - val_loss: 0.0160 - val_accuracy: 0.1239 - lr: 0.0010\n",
      "Epoch 20/25\n",
      "149/149 [==============================] - 26s 178ms/step - loss: 0.0151 - accuracy: 0.1545 - val_loss: 0.0160 - val_accuracy: 0.1211 - lr: 0.0010\n",
      "Epoch 21/25\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.0149 - accuracy: 0.1594\n",
      "Epoch 00021: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "149/149 [==============================] - 26s 177ms/step - loss: 0.0149 - accuracy: 0.1594 - val_loss: 0.0160 - val_accuracy: 0.1195 - lr: 0.0010\n",
      "Epoch 22/25\n",
      "149/149 [==============================] - 23s 153ms/step - loss: 0.0143 - accuracy: 0.1705 - val_loss: 0.0157 - val_accuracy: 0.1211 - lr: 1.0000e-04\n",
      "Epoch 23/25\n",
      "149/149 [==============================] - 23s 152ms/step - loss: 0.0142 - accuracy: 0.1780 - val_loss: 0.0157 - val_accuracy: 0.1214 - lr: 1.0000e-04\n",
      "Epoch 24/25\n",
      "149/149 [==============================] - 22s 150ms/step - loss: 0.0140 - accuracy: 0.1763 - val_loss: 0.0157 - val_accuracy: 0.1308 - lr: 1.0000e-04\n",
      "Epoch 25/25\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.0140 - accuracy: 0.1785\n",
      "Epoch 00025: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "149/149 [==============================] - 21s 141ms/step - loss: 0.0140 - accuracy: 0.1785 - val_loss: 0.0157 - val_accuracy: 0.1230 - lr: 1.0000e-04\n",
      "\n",
      "Fold 2\n",
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "batch_normalization_6 (Batch (None, 875)               3500      \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 2048)              1794048   \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 1024)              2098176   \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 1024)              4096      \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 206)               211150    \n",
      "=================================================================\n",
      "Total params: 4,110,970\n",
      "Trainable params: 4,107,172\n",
      "Non-trainable params: 3,798\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:`epsilon` argument is deprecated and will be removed, use `min_delta` instead.\n",
      "Epoch 1/25\n",
      "149/149 [==============================] - 24s 160ms/step - loss: 0.5913 - accuracy: 0.0180 - val_loss: 0.1749 - val_accuracy: 0.0338 - lr: 0.0010\n",
      "Epoch 2/25\n",
      "149/149 [==============================] - 22s 151ms/step - loss: 0.0925 - accuracy: 0.0272 - val_loss: 0.0343 - val_accuracy: 0.0401 - lr: 0.0010\n",
      "Epoch 3/25\n",
      "149/149 [==============================] - 24s 163ms/step - loss: 0.0320 - accuracy: 0.0428 - val_loss: 0.0229 - val_accuracy: 0.0477 - lr: 0.0010\n",
      "Epoch 4/25\n",
      "149/149 [==============================] - 30s 198ms/step - loss: 0.0243 - accuracy: 0.0528 - val_loss: 0.0207 - val_accuracy: 0.0569 - lr: 0.0010\n",
      "Epoch 5/25\n",
      "149/149 [==============================] - 27s 179ms/step - loss: 0.0220 - accuracy: 0.0626 - val_loss: 0.0194 - val_accuracy: 0.0642 - lr: 0.0010\n",
      "Epoch 6/25\n",
      "149/149 [==============================] - 22s 150ms/step - loss: 0.0206 - accuracy: 0.0721 - val_loss: 0.0187 - val_accuracy: 0.0739 - lr: 0.0010\n",
      "Epoch 7/25\n",
      "149/149 [==============================] - 23s 151ms/step - loss: 0.0198 - accuracy: 0.0834 - val_loss: 0.0182 - val_accuracy: 0.0869 - lr: 0.0010\n",
      "Epoch 8/25\n",
      "149/149 [==============================] - 24s 162ms/step - loss: 0.0193 - accuracy: 0.0923 - val_loss: 0.0178 - val_accuracy: 0.0869 - lr: 0.0010\n",
      "Epoch 9/25\n",
      "149/149 [==============================] - 28s 187ms/step - loss: 0.0188 - accuracy: 0.0944 - val_loss: 0.0175 - val_accuracy: 0.0892 - lr: 0.0010\n",
      "Epoch 10/25\n",
      "149/149 [==============================] - 27s 181ms/step - loss: 0.0189 - accuracy: 0.0955 - val_loss: 0.0172 - val_accuracy: 0.0890 - lr: 0.0010\n",
      "Epoch 11/25\n",
      "149/149 [==============================] - 22s 145ms/step - loss: 0.0184 - accuracy: 0.1035 - val_loss: 0.0170 - val_accuracy: 0.0974 - lr: 0.0010\n",
      "Epoch 12/25\n",
      "149/149 [==============================] - 22s 145ms/step - loss: 0.0178 - accuracy: 0.1052 - val_loss: 0.0171 - val_accuracy: 0.1176 - lr: 0.0010\n",
      "Epoch 13/25\n",
      "149/149 [==============================] - 21s 140ms/step - loss: 0.0175 - accuracy: 0.1103 - val_loss: 0.0165 - val_accuracy: 0.1226 - lr: 0.0010\n",
      "Epoch 14/25\n",
      "149/149 [==============================] - 21s 143ms/step - loss: 0.0169 - accuracy: 0.1174 - val_loss: 0.0168 - val_accuracy: 0.1337 - lr: 0.0010\n",
      "Epoch 15/25\n",
      "149/149 [==============================] - 20s 133ms/step - loss: 0.0170 - accuracy: 0.1160 - val_loss: 0.0162 - val_accuracy: 0.1020 - lr: 0.0010\n",
      "Epoch 16/25\n",
      "149/149 [==============================] - 24s 163ms/step - loss: 0.0164 - accuracy: 0.1209 - val_loss: 0.0159 - val_accuracy: 0.1167 - lr: 0.0010\n",
      "Epoch 17/25\n",
      "149/149 [==============================] - 28s 188ms/step - loss: 0.0160 - accuracy: 0.1254 - val_loss: 0.0158 - val_accuracy: 0.1071 - lr: 0.0010\n",
      "Epoch 18/25\n",
      "149/149 [==============================] - 21s 144ms/step - loss: 0.0159 - accuracy: 0.1334 - val_loss: 0.0160 - val_accuracy: 0.1176 - lr: 0.0010\n",
      "Epoch 19/25\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.0156 - accuracy: 0.1389\n",
      "Epoch 00019: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "149/149 [==============================] - 22s 149ms/step - loss: 0.0156 - accuracy: 0.1389 - val_loss: 0.0159 - val_accuracy: 0.1235 - lr: 0.0010\n",
      "Epoch 20/25\n",
      "149/149 [==============================] - 25s 170ms/step - loss: 0.0153 - accuracy: 0.1461 - val_loss: 0.0156 - val_accuracy: 0.1184 - lr: 1.0000e-04\n",
      "Epoch 21/25\n",
      "149/149 [==============================] - 23s 157ms/step - loss: 0.0151 - accuracy: 0.1498 - val_loss: 0.0155 - val_accuracy: 0.1186 - lr: 1.0000e-04\n",
      "Epoch 22/25\n",
      "149/149 [==============================] - 24s 159ms/step - loss: 0.0150 - accuracy: 0.1476 - val_loss: 0.0155 - val_accuracy: 0.1172 - lr: 1.0000e-04\n",
      "Epoch 23/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "149/149 [==============================] - 22s 144ms/step - loss: 0.0148 - accuracy: 0.1533 - val_loss: 0.0155 - val_accuracy: 0.1190 - lr: 1.0000e-04\n",
      "Epoch 24/25\n",
      "149/149 [==============================] - 21s 140ms/step - loss: 0.0148 - accuracy: 0.1527 - val_loss: 0.0155 - val_accuracy: 0.1207 - lr: 1.0000e-04\n",
      "Epoch 25/25\n",
      "149/149 [==============================] - 19s 127ms/step - loss: 0.0146 - accuracy: 0.1594 - val_loss: 0.0154 - val_accuracy: 0.1195 - lr: 1.0000e-04\n",
      "\n",
      "Fold 3\n",
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "batch_normalization_8 (Batch (None, 875)               3500      \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 2048)              1794048   \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 1024)              2098176   \n",
      "_________________________________________________________________\n",
      "batch_normalization_9 (Batch (None, 1024)              4096      \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 206)               211150    \n",
      "=================================================================\n",
      "Total params: 4,110,970\n",
      "Trainable params: 4,107,172\n",
      "Non-trainable params: 3,798\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:`epsilon` argument is deprecated and will be removed, use `min_delta` instead.\n",
      "Epoch 1/25\n",
      "149/149 [==============================] - 18s 122ms/step - loss: 0.5946 - accuracy: 0.0169 - val_loss: 0.1696 - val_accuracy: 0.0273 - lr: 0.0010\n",
      "Epoch 2/25\n",
      "149/149 [==============================] - 21s 140ms/step - loss: 0.0938 - accuracy: 0.0292 - val_loss: 0.0339 - val_accuracy: 0.0781 - lr: 0.0010\n",
      "Epoch 3/25\n",
      "149/149 [==============================] - 21s 143ms/step - loss: 0.0322 - accuracy: 0.0496 - val_loss: 0.0246 - val_accuracy: 0.0829 - lr: 0.0010\n",
      "Epoch 4/25\n",
      "149/149 [==============================] - 25s 167ms/step - loss: 0.0244 - accuracy: 0.0576 - val_loss: 0.0216 - val_accuracy: 0.0594 - lr: 0.0010\n",
      "Epoch 5/25\n",
      "149/149 [==============================] - 25s 165ms/step - loss: 0.0215 - accuracy: 0.0647 - val_loss: 0.0197 - val_accuracy: 0.0974 - lr: 0.0010\n",
      "Epoch 6/25\n",
      "149/149 [==============================] - 22s 148ms/step - loss: 0.0204 - accuracy: 0.0737 - val_loss: 0.0192 - val_accuracy: 0.1004 - lr: 0.0010\n",
      "Epoch 7/25\n",
      "149/149 [==============================] - 20s 131ms/step - loss: 0.0197 - accuracy: 0.0829 - val_loss: 0.0188 - val_accuracy: 0.0771 - lr: 0.0010\n",
      "Epoch 8/25\n",
      "149/149 [==============================] - 19s 127ms/step - loss: 0.0190 - accuracy: 0.0907 - val_loss: 0.0185 - val_accuracy: 0.0943 - lr: 0.0010\n",
      "Epoch 9/25\n",
      "149/149 [==============================] - 19s 128ms/step - loss: 0.0184 - accuracy: 0.0944 - val_loss: 0.0181 - val_accuracy: 0.0865 - lr: 0.0010\n",
      "Epoch 10/25\n",
      "149/149 [==============================] - 19s 125ms/step - loss: 0.0180 - accuracy: 0.1016 - val_loss: 0.0177 - val_accuracy: 0.0953 - lr: 0.0010\n",
      "Epoch 11/25\n",
      "149/149 [==============================] - 19s 126ms/step - loss: 0.0176 - accuracy: 0.1085 - val_loss: 0.0176 - val_accuracy: 0.1281 - lr: 0.0010\n",
      "Epoch 12/25\n",
      "149/149 [==============================] - 20s 132ms/step - loss: 0.0173 - accuracy: 0.1099 - val_loss: 0.0171 - val_accuracy: 0.0947 - lr: 0.0010\n",
      "Epoch 13/25\n",
      "149/149 [==============================] - 19s 129ms/step - loss: 0.0170 - accuracy: 0.1104 - val_loss: 0.0171 - val_accuracy: 0.1041 - lr: 0.0010\n",
      "Epoch 14/25\n",
      "149/149 [==============================] - 19s 129ms/step - loss: 0.0166 - accuracy: 0.1194 - val_loss: 0.0169 - val_accuracy: 0.1117 - lr: 0.0010\n",
      "Epoch 15/25\n",
      "149/149 [==============================] - 20s 135ms/step - loss: 0.0166 - accuracy: 0.1251 - val_loss: 0.0166 - val_accuracy: 0.1077 - lr: 0.0010\n",
      "Epoch 16/25\n",
      "149/149 [==============================] - 21s 143ms/step - loss: 0.0161 - accuracy: 0.1298 - val_loss: 0.0165 - val_accuracy: 0.1111 - lr: 0.0010\n",
      "Epoch 17/25\n",
      "149/149 [==============================] - 22s 151ms/step - loss: 0.0162 - accuracy: 0.1347 - val_loss: 0.0170 - val_accuracy: 0.1098 - lr: 0.0010\n",
      "Epoch 18/25\n",
      "149/149 [==============================] - 19s 128ms/step - loss: 0.0158 - accuracy: 0.1389 - val_loss: 0.0165 - val_accuracy: 0.1186 - lr: 0.0010\n",
      "Epoch 19/25\n",
      "149/149 [==============================] - 19s 130ms/step - loss: 0.0152 - accuracy: 0.1450 - val_loss: 0.0160 - val_accuracy: 0.1205 - lr: 0.0010\n",
      "Epoch 20/25\n",
      "149/149 [==============================] - 19s 126ms/step - loss: 0.0151 - accuracy: 0.1533 - val_loss: 0.0163 - val_accuracy: 0.1224 - lr: 0.0010\n",
      "Epoch 21/25\n",
      "149/149 [==============================] - 21s 140ms/step - loss: 0.0147 - accuracy: 0.1606 - val_loss: 0.0164 - val_accuracy: 0.1188 - lr: 0.0010\n",
      "Epoch 22/25\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.0142 - accuracy: 0.1662\n",
      "Epoch 00022: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "149/149 [==============================] - 20s 137ms/step - loss: 0.0142 - accuracy: 0.1662 - val_loss: 0.0161 - val_accuracy: 0.1365 - lr: 0.0010\n",
      "Epoch 23/25\n",
      "149/149 [==============================] - 20s 131ms/step - loss: 0.0135 - accuracy: 0.1885 - val_loss: 0.0159 - val_accuracy: 0.1304 - lr: 1.0000e-04\n",
      "Epoch 24/25\n",
      "149/149 [==============================] - 20s 133ms/step - loss: 0.0133 - accuracy: 0.1905 - val_loss: 0.0159 - val_accuracy: 0.1274 - lr: 1.0000e-04\n",
      "Epoch 25/25\n",
      "149/149 [==============================] - 19s 131ms/step - loss: 0.0132 - accuracy: 0.1867 - val_loss: 0.0159 - val_accuracy: 0.1266 - lr: 1.0000e-04\n",
      "\n",
      "Fold 4\n",
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "batch_normalization_10 (Batc (None, 875)               3500      \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 2048)              1794048   \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 1024)              2098176   \n",
      "_________________________________________________________________\n",
      "batch_normalization_11 (Batc (None, 1024)              4096      \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 206)               211150    \n",
      "=================================================================\n",
      "Total params: 4,110,970\n",
      "Trainable params: 4,107,172\n",
      "Non-trainable params: 3,798\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:`epsilon` argument is deprecated and will be removed, use `min_delta` instead.\n",
      "Epoch 1/25\n",
      "149/149 [==============================] - 20s 135ms/step - loss: 0.5882 - accuracy: 0.0124 - val_loss: 0.1699 - val_accuracy: 0.0134 - lr: 0.0010\n",
      "Epoch 2/25\n",
      "149/149 [==============================] - 20s 134ms/step - loss: 0.0941 - accuracy: 0.0263 - val_loss: 0.0358 - val_accuracy: 0.0640 - lr: 0.0010\n",
      "Epoch 3/25\n",
      "149/149 [==============================] - 20s 132ms/step - loss: 0.0324 - accuracy: 0.0450 - val_loss: 0.0244 - val_accuracy: 0.0554 - lr: 0.0010\n",
      "Epoch 4/25\n",
      "149/149 [==============================] - 20s 135ms/step - loss: 0.0243 - accuracy: 0.0541 - val_loss: 0.0215 - val_accuracy: 0.0836 - lr: 0.0010\n",
      "Epoch 5/25\n",
      "149/149 [==============================] - 21s 140ms/step - loss: 0.0219 - accuracy: 0.0619 - val_loss: 0.0202 - val_accuracy: 0.0691 - lr: 0.0010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/25\n",
      "149/149 [==============================] - 17s 116ms/step - loss: 0.0206 - accuracy: 0.0709 - val_loss: 0.0194 - val_accuracy: 0.0842 - lr: 0.0010\n",
      "Epoch 7/25\n",
      "149/149 [==============================] - 18s 118ms/step - loss: 0.0199 - accuracy: 0.0800 - val_loss: 0.0188 - val_accuracy: 0.1077 - lr: 0.0010\n",
      "Epoch 8/25\n",
      "149/149 [==============================] - 18s 118ms/step - loss: 0.0193 - accuracy: 0.0901 - val_loss: 0.0186 - val_accuracy: 0.1088 - lr: 0.0010\n",
      "Epoch 9/25\n",
      "149/149 [==============================] - 18s 118ms/step - loss: 0.0187 - accuracy: 0.0919 - val_loss: 0.0180 - val_accuracy: 0.1105 - lr: 0.0010\n",
      "Epoch 10/25\n",
      "149/149 [==============================] - 17s 117ms/step - loss: 0.0183 - accuracy: 0.0982 - val_loss: 0.0179 - val_accuracy: 0.1079 - lr: 0.0010\n",
      "Epoch 11/25\n",
      "149/149 [==============================] - 17s 116ms/step - loss: 0.0179 - accuracy: 0.1042 - val_loss: 0.0172 - val_accuracy: 0.0966 - lr: 0.0010\n",
      "Epoch 12/25\n",
      "149/149 [==============================] - 18s 121ms/step - loss: 0.0176 - accuracy: 0.1061 - val_loss: 0.0169 - val_accuracy: 0.1025 - lr: 0.0010\n",
      "Epoch 13/25\n",
      "149/149 [==============================] - 20s 131ms/step - loss: 0.0173 - accuracy: 0.1125 - val_loss: 0.0168 - val_accuracy: 0.1039 - lr: 0.0010\n",
      "Epoch 14/25\n",
      "149/149 [==============================] - 18s 118ms/step - loss: 0.0170 - accuracy: 0.1168 - val_loss: 0.0167 - val_accuracy: 0.1168 - lr: 0.0010\n",
      "Epoch 15/25\n",
      "149/149 [==============================] - 17s 116ms/step - loss: 0.0165 - accuracy: 0.1238 - val_loss: 0.0164 - val_accuracy: 0.1300 - lr: 0.0010\n",
      "Epoch 16/25\n",
      "149/149 [==============================] - 18s 118ms/step - loss: 0.0162 - accuracy: 0.1286 - val_loss: 0.0162 - val_accuracy: 0.1128 - lr: 0.0010\n",
      "Epoch 17/25\n",
      "149/149 [==============================] - 17s 116ms/step - loss: 0.0158 - accuracy: 0.1315 - val_loss: 0.0161 - val_accuracy: 0.1159 - lr: 0.0010\n",
      "Epoch 18/25\n",
      "149/149 [==============================] - 19s 126ms/step - loss: 0.0157 - accuracy: 0.1385 - val_loss: 0.0162 - val_accuracy: 0.1193 - lr: 0.0010\n",
      "Epoch 19/25\n",
      "149/149 [==============================] - 18s 119ms/step - loss: 0.0153 - accuracy: 0.1441 - val_loss: 0.0160 - val_accuracy: 0.1172 - lr: 0.0010\n",
      "Epoch 20/25\n",
      "149/149 [==============================] - 19s 129ms/step - loss: 0.0152 - accuracy: 0.1559 - val_loss: 0.0161 - val_accuracy: 0.1195 - lr: 0.0010\n",
      "Epoch 21/25\n",
      "149/149 [==============================] - 19s 127ms/step - loss: 0.0148 - accuracy: 0.1535 - val_loss: 0.0157 - val_accuracy: 0.1390 - lr: 0.0010\n",
      "Epoch 22/25\n",
      "149/149 [==============================] - 18s 123ms/step - loss: 0.0143 - accuracy: 0.1691 - val_loss: 0.0159 - val_accuracy: 0.1214 - lr: 0.0010\n",
      "Epoch 23/25\n",
      "149/149 [==============================] - 19s 127ms/step - loss: 0.0140 - accuracy: 0.1741 - val_loss: 0.0158 - val_accuracy: 0.1266 - lr: 0.0010\n",
      "Epoch 24/25\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.0135 - accuracy: 0.1868\n",
      "Epoch 00024: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "149/149 [==============================] - 19s 125ms/step - loss: 0.0135 - accuracy: 0.1868 - val_loss: 0.0158 - val_accuracy: 0.1233 - lr: 0.0010\n",
      "Epoch 25/25\n",
      "149/149 [==============================] - 19s 126ms/step - loss: 0.0128 - accuracy: 0.2046 - val_loss: 0.0157 - val_accuracy: 0.1268 - lr: 1.0000e-04\n",
      "\n",
      "Fold 0\n",
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "batch_normalization_12 (Batc (None, 875)               3500      \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 2048)              1794048   \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 1024)              2098176   \n",
      "_________________________________________________________________\n",
      "batch_normalization_13 (Batc (None, 1024)              4096      \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 206)               211150    \n",
      "=================================================================\n",
      "Total params: 4,110,970\n",
      "Trainable params: 4,107,172\n",
      "Non-trainable params: 3,798\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:`epsilon` argument is deprecated and will be removed, use `min_delta` instead.\n",
      "Epoch 1/25\n",
      "149/149 [==============================] - 19s 128ms/step - loss: 0.5902 - accuracy: 0.0146 - val_loss: 0.1718 - val_accuracy: 0.0395 - lr: 0.0010\n",
      "Epoch 2/25\n",
      "149/149 [==============================] - 19s 128ms/step - loss: 0.0949 - accuracy: 0.0249 - val_loss: 0.0363 - val_accuracy: 0.0445 - lr: 0.0010\n",
      "Epoch 3/25\n",
      "149/149 [==============================] - 20s 134ms/step - loss: 0.0325 - accuracy: 0.0429 - val_loss: 0.0241 - val_accuracy: 0.0426 - lr: 0.0010\n",
      "Epoch 4/25\n",
      "149/149 [==============================] - 22s 148ms/step - loss: 0.0244 - accuracy: 0.0552 - val_loss: 0.0211 - val_accuracy: 0.0472 - lr: 0.0010\n",
      "Epoch 5/25\n",
      "149/149 [==============================] - 20s 133ms/step - loss: 0.0220 - accuracy: 0.0618 - val_loss: 0.0198 - val_accuracy: 0.0628 - lr: 0.0010\n",
      "Epoch 6/25\n",
      "149/149 [==============================] - 20s 137ms/step - loss: 0.0207 - accuracy: 0.0728 - val_loss: 0.0191 - val_accuracy: 0.0731 - lr: 0.0010\n",
      "Epoch 7/25\n",
      "149/149 [==============================] - 21s 142ms/step - loss: 0.0200 - accuracy: 0.0807 - val_loss: 0.0186 - val_accuracy: 0.0747 - lr: 0.0010\n",
      "Epoch 8/25\n",
      "149/149 [==============================] - 19s 126ms/step - loss: 0.0192 - accuracy: 0.0892 - val_loss: 0.0184 - val_accuracy: 0.1001 - lr: 0.0010\n",
      "Epoch 9/25\n",
      "149/149 [==============================] - 20s 133ms/step - loss: 0.0187 - accuracy: 0.0930 - val_loss: 0.0178 - val_accuracy: 0.0909 - lr: 0.0010\n",
      "Epoch 10/25\n",
      "149/149 [==============================] - 20s 135ms/step - loss: 0.0182 - accuracy: 0.0997 - val_loss: 0.0173 - val_accuracy: 0.1142 - lr: 0.0010\n",
      "Epoch 11/25\n",
      "149/149 [==============================] - 21s 138ms/step - loss: 0.0178 - accuracy: 0.1064 - val_loss: 0.0170 - val_accuracy: 0.1014 - lr: 0.0010\n",
      "Epoch 12/25\n",
      "149/149 [==============================] - 25s 168ms/step - loss: 0.0175 - accuracy: 0.1083 - val_loss: 0.0167 - val_accuracy: 0.1125 - lr: 0.0010\n",
      "Epoch 13/25\n",
      "149/149 [==============================] - 27s 178ms/step - loss: 0.0173 - accuracy: 0.1174 - val_loss: 0.0165 - val_accuracy: 0.1006 - lr: 0.0010\n",
      "Epoch 14/25\n",
      "149/149 [==============================] - 20s 135ms/step - loss: 0.0168 - accuracy: 0.1231 - val_loss: 0.0170 - val_accuracy: 0.0976 - lr: 0.0010\n",
      "Epoch 15/25\n",
      "149/149 [==============================] - 21s 138ms/step - loss: 0.0167 - accuracy: 0.1226 - val_loss: 0.0164 - val_accuracy: 0.1178 - lr: 0.0010\n",
      "Epoch 16/25\n",
      "149/149 [==============================] - 20s 135ms/step - loss: 0.0162 - accuracy: 0.1273 - val_loss: 0.0163 - val_accuracy: 0.1058 - lr: 0.0010\n",
      "Epoch 17/25\n",
      "149/149 [==============================] - 21s 138ms/step - loss: 0.0161 - accuracy: 0.1330 - val_loss: 0.0161 - val_accuracy: 0.1081 - lr: 0.0010\n",
      "Epoch 18/25\n",
      "149/149 [==============================] - 21s 140ms/step - loss: 0.0159 - accuracy: 0.1361 - val_loss: 0.0160 - val_accuracy: 0.1113 - lr: 0.0010\n",
      "Epoch 19/25\n",
      "149/149 [==============================] - 24s 160ms/step - loss: 0.0154 - accuracy: 0.1425 - val_loss: 0.0159 - val_accuracy: 0.1136 - lr: 0.0010\n",
      "Epoch 20/25\n",
      "149/149 [==============================] - 25s 168ms/step - loss: 0.0151 - accuracy: 0.1458 - val_loss: 0.0157 - val_accuracy: 0.1193 - lr: 0.0010\n",
      "Epoch 21/25\n",
      "149/149 [==============================] - 21s 142ms/step - loss: 0.0146 - accuracy: 0.1550 - val_loss: 0.0158 - val_accuracy: 0.1163 - lr: 0.0010\n",
      "Epoch 22/25\n",
      "149/149 [==============================] - 20s 134ms/step - loss: 0.0143 - accuracy: 0.1622 - val_loss: 0.0164 - val_accuracy: 0.1241 - lr: 0.0010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/25\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.0141 - accuracy: 0.1710\n",
      "Epoch 00023: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "149/149 [==============================] - 20s 134ms/step - loss: 0.0141 - accuracy: 0.1710 - val_loss: 0.0158 - val_accuracy: 0.1222 - lr: 0.0010\n",
      "Epoch 24/25\n",
      "149/149 [==============================] - 19s 124ms/step - loss: 0.0133 - accuracy: 0.1877 - val_loss: 0.0155 - val_accuracy: 0.1249 - lr: 1.0000e-04\n",
      "Epoch 25/25\n",
      "149/149 [==============================] - 18s 121ms/step - loss: 0.0131 - accuracy: 0.1939 - val_loss: 0.0155 - val_accuracy: 0.1281 - lr: 1.0000e-04\n",
      "\n",
      "Fold 1\n",
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "batch_normalization_14 (Batc (None, 875)               3500      \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 2048)              1794048   \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 1024)              2098176   \n",
      "_________________________________________________________________\n",
      "batch_normalization_15 (Batc (None, 1024)              4096      \n",
      "_________________________________________________________________\n",
      "dropout_15 (Dropout)         (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 206)               211150    \n",
      "=================================================================\n",
      "Total params: 4,110,970\n",
      "Trainable params: 4,107,172\n",
      "Non-trainable params: 3,798\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:`epsilon` argument is deprecated and will be removed, use `min_delta` instead.\n",
      "Epoch 1/25\n",
      "149/149 [==============================] - 18s 124ms/step - loss: 0.5898 - accuracy: 0.0156 - val_loss: 0.1814 - val_accuracy: 0.0317 - lr: 0.0010\n",
      "Epoch 2/25\n",
      "149/149 [==============================] - 19s 126ms/step - loss: 0.0941 - accuracy: 0.0247 - val_loss: 0.0379 - val_accuracy: 0.0418 - lr: 0.0010\n",
      "Epoch 3/25\n",
      "149/149 [==============================] - 18s 122ms/step - loss: 0.0325 - accuracy: 0.0417 - val_loss: 0.0243 - val_accuracy: 0.0773 - lr: 0.0010\n",
      "Epoch 4/25\n",
      "149/149 [==============================] - 18s 121ms/step - loss: 0.0243 - accuracy: 0.0553 - val_loss: 0.0217 - val_accuracy: 0.0519 - lr: 0.0010\n",
      "Epoch 5/25\n",
      "149/149 [==============================] - 18s 121ms/step - loss: 0.0217 - accuracy: 0.0635 - val_loss: 0.0201 - val_accuracy: 0.0938 - lr: 0.0010\n",
      "Epoch 6/25\n",
      "149/149 [==============================] - 18s 121ms/step - loss: 0.0207 - accuracy: 0.0721 - val_loss: 0.0195 - val_accuracy: 0.0722 - lr: 0.0010\n",
      "Epoch 7/25\n",
      "149/149 [==============================] - 18s 123ms/step - loss: 0.0203 - accuracy: 0.0823 - val_loss: 0.0191 - val_accuracy: 0.0796 - lr: 0.0010\n",
      "Epoch 8/25\n",
      "149/149 [==============================] - 18s 121ms/step - loss: 0.0193 - accuracy: 0.0865 - val_loss: 0.0183 - val_accuracy: 0.1132 - lr: 0.0010\n",
      "Epoch 9/25\n",
      "149/149 [==============================] - 22s 146ms/step - loss: 0.0186 - accuracy: 0.0984 - val_loss: 0.0184 - val_accuracy: 0.1174 - lr: 0.0010\n",
      "Epoch 10/25\n",
      "149/149 [==============================] - 24s 160ms/step - loss: 0.0185 - accuracy: 0.0984 - val_loss: 0.0180 - val_accuracy: 0.0953 - lr: 0.0010\n",
      "Epoch 11/25\n",
      "149/149 [==============================] - 19s 131ms/step - loss: 0.0178 - accuracy: 0.1058 - val_loss: 0.0173 - val_accuracy: 0.0980 - lr: 0.0010\n",
      "Epoch 12/25\n",
      "149/149 [==============================] - 20s 136ms/step - loss: 0.0174 - accuracy: 0.1101 - val_loss: 0.0172 - val_accuracy: 0.1140 - lr: 0.0010\n",
      "Epoch 13/25\n",
      "149/149 [==============================] - 20s 133ms/step - loss: 0.0171 - accuracy: 0.1141 - val_loss: 0.0168 - val_accuracy: 0.1125 - lr: 0.0010\n",
      "Epoch 14/25\n",
      "149/149 [==============================] - 20s 135ms/step - loss: 0.0168 - accuracy: 0.1201 - val_loss: 0.0169 - val_accuracy: 0.1014 - lr: 0.0010\n",
      "Epoch 15/25\n",
      "149/149 [==============================] - 20s 134ms/step - loss: 0.0167 - accuracy: 0.1203 - val_loss: 0.0167 - val_accuracy: 0.1035 - lr: 0.0010\n",
      "Epoch 16/25\n",
      "149/149 [==============================] - 20s 133ms/step - loss: 0.0163 - accuracy: 0.1310 - val_loss: 0.0163 - val_accuracy: 0.1098 - lr: 0.0010\n",
      "Epoch 17/25\n",
      "149/149 [==============================] - 20s 135ms/step - loss: 0.0158 - accuracy: 0.1356 - val_loss: 0.0162 - val_accuracy: 0.1245 - lr: 0.0010\n",
      "Epoch 18/25\n",
      "149/149 [==============================] - 19s 130ms/step - loss: 0.0159 - accuracy: 0.1347 - val_loss: 0.0163 - val_accuracy: 0.1277 - lr: 0.0010\n",
      "Epoch 19/25\n",
      "149/149 [==============================] - 19s 130ms/step - loss: 0.0154 - accuracy: 0.1394 - val_loss: 0.0161 - val_accuracy: 0.1144 - lr: 0.0010\n",
      "Epoch 20/25\n",
      "149/149 [==============================] - 20s 134ms/step - loss: 0.0151 - accuracy: 0.1498 - val_loss: 0.0160 - val_accuracy: 0.1193 - lr: 0.0010\n",
      "Epoch 21/25\n",
      "149/149 [==============================] - 20s 133ms/step - loss: 0.0147 - accuracy: 0.1553 - val_loss: 0.0164 - val_accuracy: 0.1195 - lr: 0.0010\n",
      "Epoch 22/25\n",
      "149/149 [==============================] - 20s 133ms/step - loss: 0.0143 - accuracy: 0.1652 - val_loss: 0.0160 - val_accuracy: 0.1245 - lr: 0.0010\n",
      "Epoch 23/25\n",
      "149/149 [==============================] - 22s 146ms/step - loss: 0.0139 - accuracy: 0.1736 - val_loss: 0.0158 - val_accuracy: 0.1197 - lr: 0.0010\n",
      "Epoch 24/25\n",
      "149/149 [==============================] - 20s 134ms/step - loss: 0.0135 - accuracy: 0.1859 - val_loss: 0.0158 - val_accuracy: 0.1209 - lr: 0.0010\n",
      "Epoch 25/25\n",
      "149/149 [==============================] - 24s 163ms/step - loss: 0.0132 - accuracy: 0.1938 - val_loss: 0.0160 - val_accuracy: 0.1222 - lr: 0.0010\n",
      "\n",
      "Fold 2\n",
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "batch_normalization_16 (Batc (None, 875)               3500      \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 2048)              1794048   \n",
      "_________________________________________________________________\n",
      "dropout_16 (Dropout)         (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_25 (Dense)             (None, 1024)              2098176   \n",
      "_________________________________________________________________\n",
      "batch_normalization_17 (Batc (None, 1024)              4096      \n",
      "_________________________________________________________________\n",
      "dropout_17 (Dropout)         (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_26 (Dense)             (None, 206)               211150    \n",
      "=================================================================\n",
      "Total params: 4,110,970\n",
      "Trainable params: 4,107,172\n",
      "Non-trainable params: 3,798\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:`epsilon` argument is deprecated and will be removed, use `min_delta` instead.\n",
      "Epoch 1/25\n",
      "149/149 [==============================] - 20s 135ms/step - loss: 0.5899 - accuracy: 0.0159 - val_loss: 0.1756 - val_accuracy: 0.0220 - lr: 0.0010\n",
      "Epoch 2/25\n",
      "149/149 [==============================] - 21s 139ms/step - loss: 0.0927 - accuracy: 0.0254 - val_loss: 0.0335 - val_accuracy: 0.0477 - lr: 0.0010\n",
      "Epoch 3/25\n",
      "149/149 [==============================] - 23s 151ms/step - loss: 0.0324 - accuracy: 0.0422 - val_loss: 0.0236 - val_accuracy: 0.0764 - lr: 0.0010\n",
      "Epoch 4/25\n",
      "149/149 [==============================] - 26s 172ms/step - loss: 0.0243 - accuracy: 0.0525 - val_loss: 0.0211 - val_accuracy: 0.0873 - lr: 0.0010\n",
      "Epoch 5/25\n",
      "149/149 [==============================] - 21s 143ms/step - loss: 0.0221 - accuracy: 0.0588 - val_loss: 0.0200 - val_accuracy: 0.0930 - lr: 0.0010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/25\n",
      "149/149 [==============================] - 20s 135ms/step - loss: 0.0210 - accuracy: 0.0664 - val_loss: 0.0192 - val_accuracy: 0.1031 - lr: 0.0010\n",
      "Epoch 7/25\n",
      "149/149 [==============================] - 21s 143ms/step - loss: 0.0200 - accuracy: 0.0787 - val_loss: 0.0187 - val_accuracy: 0.1144 - lr: 0.0010\n",
      "Epoch 8/25\n",
      "149/149 [==============================] - 20s 135ms/step - loss: 0.0196 - accuracy: 0.0880 - val_loss: 0.0183 - val_accuracy: 0.0852 - lr: 0.0010\n",
      "Epoch 9/25\n",
      "149/149 [==============================] - 20s 131ms/step - loss: 0.0189 - accuracy: 0.0914 - val_loss: 0.0177 - val_accuracy: 0.0934 - lr: 0.0010\n",
      "Epoch 10/25\n",
      "149/149 [==============================] - 22s 145ms/step - loss: 0.0186 - accuracy: 0.0982 - val_loss: 0.0173 - val_accuracy: 0.0970 - lr: 0.0010\n",
      "Epoch 11/25\n",
      "149/149 [==============================] - 19s 130ms/step - loss: 0.0179 - accuracy: 0.1029 - val_loss: 0.0171 - val_accuracy: 0.0945 - lr: 0.0010\n",
      "Epoch 12/25\n",
      "149/149 [==============================] - 20s 133ms/step - loss: 0.0175 - accuracy: 0.1069 - val_loss: 0.0167 - val_accuracy: 0.0997 - lr: 0.0010\n",
      "Epoch 13/25\n",
      "149/149 [==============================] - 22s 148ms/step - loss: 0.0174 - accuracy: 0.1133 - val_loss: 0.0165 - val_accuracy: 0.1025 - lr: 0.0010\n",
      "Epoch 14/25\n",
      "149/149 [==============================] - 21s 143ms/step - loss: 0.0173 - accuracy: 0.1142 - val_loss: 0.0163 - val_accuracy: 0.1295 - lr: 0.0010\n",
      "Epoch 15/25\n",
      "149/149 [==============================] - 26s 174ms/step - loss: 0.0170 - accuracy: 0.1205 - val_loss: 0.0171 - val_accuracy: 0.1109 - lr: 0.0010\n",
      "Epoch 16/25\n",
      "149/149 [==============================] - 22s 145ms/step - loss: 0.0165 - accuracy: 0.1210 - val_loss: 0.0160 - val_accuracy: 0.1314 - lr: 0.0010\n",
      "Epoch 17/25\n",
      "149/149 [==============================] - 20s 134ms/step - loss: 0.0161 - accuracy: 0.1290 - val_loss: 0.0159 - val_accuracy: 0.1172 - lr: 0.0010\n",
      "Epoch 18/25\n",
      "149/149 [==============================] - 23s 154ms/step - loss: 0.0157 - accuracy: 0.1331 - val_loss: 0.0158 - val_accuracy: 0.1207 - lr: 0.0010\n",
      "Epoch 19/25\n",
      "149/149 [==============================] - 21s 140ms/step - loss: 0.0153 - accuracy: 0.1410 - val_loss: 0.0156 - val_accuracy: 0.1214 - lr: 0.0010\n",
      "Epoch 20/25\n",
      "149/149 [==============================] - 20s 131ms/step - loss: 0.0152 - accuracy: 0.1485 - val_loss: 0.0156 - val_accuracy: 0.1285 - lr: 0.0010\n",
      "Epoch 21/25\n",
      "149/149 [==============================] - 19s 127ms/step - loss: 0.0150 - accuracy: 0.1519 - val_loss: 0.0157 - val_accuracy: 0.1226 - lr: 0.0010\n",
      "Epoch 22/25\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.0150 - accuracy: 0.1555\n",
      "Epoch 00022: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "149/149 [==============================] - 19s 129ms/step - loss: 0.0150 - accuracy: 0.1555 - val_loss: 0.0156 - val_accuracy: 0.1226 - lr: 0.0010\n",
      "Epoch 23/25\n",
      "149/149 [==============================] - 19s 127ms/step - loss: 0.0142 - accuracy: 0.1711 - val_loss: 0.0154 - val_accuracy: 0.1279 - lr: 1.0000e-04\n",
      "Epoch 24/25\n",
      "149/149 [==============================] - 19s 126ms/step - loss: 0.0140 - accuracy: 0.1701 - val_loss: 0.0154 - val_accuracy: 0.1279 - lr: 1.0000e-04\n",
      "Epoch 25/25\n",
      "149/149 [==============================] - 20s 131ms/step - loss: 0.0139 - accuracy: 0.1745 - val_loss: 0.0153 - val_accuracy: 0.1316 - lr: 1.0000e-04\n",
      "\n",
      "Fold 3\n",
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "batch_normalization_18 (Batc (None, 875)               3500      \n",
      "_________________________________________________________________\n",
      "dense_27 (Dense)             (None, 2048)              1794048   \n",
      "_________________________________________________________________\n",
      "dropout_18 (Dropout)         (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_28 (Dense)             (None, 1024)              2098176   \n",
      "_________________________________________________________________\n",
      "batch_normalization_19 (Batc (None, 1024)              4096      \n",
      "_________________________________________________________________\n",
      "dropout_19 (Dropout)         (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_29 (Dense)             (None, 206)               211150    \n",
      "=================================================================\n",
      "Total params: 4,110,970\n",
      "Trainable params: 4,107,172\n",
      "Non-trainable params: 3,798\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:`epsilon` argument is deprecated and will be removed, use `min_delta` instead.\n",
      "Epoch 1/25\n",
      "149/149 [==============================] - 19s 130ms/step - loss: 0.5933 - accuracy: 0.0185 - val_loss: 0.1582 - val_accuracy: 0.0600 - lr: 0.0010\n",
      "Epoch 2/25\n",
      "149/149 [==============================] - 20s 132ms/step - loss: 0.0925 - accuracy: 0.0311 - val_loss: 0.0357 - val_accuracy: 0.0752 - lr: 0.0010\n",
      "Epoch 3/25\n",
      "149/149 [==============================] - 20s 132ms/step - loss: 0.0322 - accuracy: 0.0439 - val_loss: 0.0241 - val_accuracy: 0.0869 - lr: 0.0010\n",
      "Epoch 4/25\n",
      "149/149 [==============================] - 21s 142ms/step - loss: 0.0239 - accuracy: 0.0588 - val_loss: 0.0210 - val_accuracy: 0.0579 - lr: 0.0010\n",
      "Epoch 5/25\n",
      "149/149 [==============================] - 22s 149ms/step - loss: 0.0221 - accuracy: 0.0630 - val_loss: 0.0200 - val_accuracy: 0.0909 - lr: 0.0010\n",
      "Epoch 6/25\n",
      "149/149 [==============================] - 20s 134ms/step - loss: 0.0207 - accuracy: 0.0721 - val_loss: 0.0194 - val_accuracy: 0.1014 - lr: 0.0010\n",
      "Epoch 7/25\n",
      "149/149 [==============================] - 19s 129ms/step - loss: 0.0199 - accuracy: 0.0802 - val_loss: 0.0187 - val_accuracy: 0.1098 - lr: 0.0010\n",
      "Epoch 8/25\n",
      "149/149 [==============================] - 19s 130ms/step - loss: 0.0195 - accuracy: 0.0881 - val_loss: 0.0183 - val_accuracy: 0.1190 - lr: 0.0010\n",
      "Epoch 9/25\n",
      "149/149 [==============================] - 20s 134ms/step - loss: 0.0188 - accuracy: 0.0952 - val_loss: 0.0180 - val_accuracy: 0.0951 - lr: 0.0010\n",
      "Epoch 10/25\n",
      "149/149 [==============================] - 19s 130ms/step - loss: 0.0184 - accuracy: 0.1011 - val_loss: 0.0178 - val_accuracy: 0.1268 - lr: 0.0010\n",
      "Epoch 11/25\n",
      "149/149 [==============================] - 20s 133ms/step - loss: 0.0178 - accuracy: 0.1079 - val_loss: 0.0174 - val_accuracy: 0.1325 - lr: 0.0010\n",
      "Epoch 12/25\n",
      "149/149 [==============================] - 20s 132ms/step - loss: 0.0177 - accuracy: 0.1140 - val_loss: 0.0172 - val_accuracy: 0.1008 - lr: 0.0010\n",
      "Epoch 13/25\n",
      "149/149 [==============================] - 20s 133ms/step - loss: 0.0172 - accuracy: 0.1168 - val_loss: 0.0168 - val_accuracy: 0.1064 - lr: 0.0010\n",
      "Epoch 14/25\n",
      "149/149 [==============================] - 20s 137ms/step - loss: 0.0170 - accuracy: 0.1194 - val_loss: 0.0166 - val_accuracy: 0.1113 - lr: 0.0010\n",
      "Epoch 15/25\n",
      "149/149 [==============================] - 19s 128ms/step - loss: 0.0168 - accuracy: 0.1230 - val_loss: 0.0168 - val_accuracy: 0.1085 - lr: 0.0010\n",
      "Epoch 16/25\n",
      "149/149 [==============================] - 20s 132ms/step - loss: 0.0164 - accuracy: 0.1256 - val_loss: 0.0164 - val_accuracy: 0.1151 - lr: 0.0010\n",
      "Epoch 17/25\n",
      "149/149 [==============================] - 20s 132ms/step - loss: 0.0160 - accuracy: 0.1321 - val_loss: 0.0162 - val_accuracy: 0.1312 - lr: 0.0010\n",
      "Epoch 18/25\n",
      "149/149 [==============================] - 20s 138ms/step - loss: 0.0156 - accuracy: 0.1408 - val_loss: 0.0161 - val_accuracy: 0.1205 - lr: 0.0010\n",
      "Epoch 19/25\n",
      "149/149 [==============================] - 21s 142ms/step - loss: 0.0154 - accuracy: 0.1466 - val_loss: 0.0161 - val_accuracy: 0.1209 - lr: 0.0010\n",
      "Epoch 20/25\n",
      "149/149 [==============================] - 23s 155ms/step - loss: 0.0150 - accuracy: 0.1533 - val_loss: 0.0159 - val_accuracy: 0.1449 - lr: 0.0010\n",
      "Epoch 21/25\n",
      "149/149 [==============================] - 21s 142ms/step - loss: 0.0146 - accuracy: 0.1610 - val_loss: 0.0159 - val_accuracy: 0.1235 - lr: 0.0010\n",
      "Epoch 22/25\n",
      "149/149 [==============================] - 22s 146ms/step - loss: 0.0142 - accuracy: 0.1721 - val_loss: 0.0163 - val_accuracy: 0.1558 - lr: 0.0010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/25\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.0141 - accuracy: 0.1748\n",
      "Epoch 00023: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "149/149 [==============================] - 21s 143ms/step - loss: 0.0141 - accuracy: 0.1748 - val_loss: 0.0158 - val_accuracy: 0.1262 - lr: 0.0010\n",
      "Epoch 24/25\n",
      "149/149 [==============================] - 18s 119ms/step - loss: 0.0132 - accuracy: 0.1926 - val_loss: 0.0157 - val_accuracy: 0.1291 - lr: 1.0000e-04\n",
      "Epoch 25/25\n",
      "149/149 [==============================] - 17s 117ms/step - loss: 0.0130 - accuracy: 0.1952 - val_loss: 0.0156 - val_accuracy: 0.1316 - lr: 1.0000e-04\n",
      "\n",
      "Fold 4\n",
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "batch_normalization_20 (Batc (None, 875)               3500      \n",
      "_________________________________________________________________\n",
      "dense_30 (Dense)             (None, 2048)              1794048   \n",
      "_________________________________________________________________\n",
      "dropout_20 (Dropout)         (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_31 (Dense)             (None, 1024)              2098176   \n",
      "_________________________________________________________________\n",
      "batch_normalization_21 (Batc (None, 1024)              4096      \n",
      "_________________________________________________________________\n",
      "dropout_21 (Dropout)         (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_32 (Dense)             (None, 206)               211150    \n",
      "=================================================================\n",
      "Total params: 4,110,970\n",
      "Trainable params: 4,107,172\n",
      "Non-trainable params: 3,798\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:`epsilon` argument is deprecated and will be removed, use `min_delta` instead.\n",
      "Epoch 1/25\n",
      "149/149 [==============================] - 17s 116ms/step - loss: 0.5869 - accuracy: 0.0152 - val_loss: 0.1662 - val_accuracy: 0.0252 - lr: 0.0010\n",
      "Epoch 2/25\n",
      "149/149 [==============================] - 18s 120ms/step - loss: 0.0937 - accuracy: 0.0270 - val_loss: 0.0341 - val_accuracy: 0.0523 - lr: 0.0010\n",
      "Epoch 3/25\n",
      "149/149 [==============================] - 23s 152ms/step - loss: 0.0322 - accuracy: 0.0438 - val_loss: 0.0239 - val_accuracy: 0.0487 - lr: 0.0010\n",
      "Epoch 4/25\n",
      "149/149 [==============================] - 20s 132ms/step - loss: 0.0241 - accuracy: 0.0563 - val_loss: 0.0210 - val_accuracy: 0.0712 - lr: 0.0010\n",
      "Epoch 5/25\n",
      "149/149 [==============================] - 22s 149ms/step - loss: 0.0219 - accuracy: 0.0643 - val_loss: 0.0198 - val_accuracy: 0.0603 - lr: 0.0010\n",
      "Epoch 6/25\n",
      "149/149 [==============================] - 20s 135ms/step - loss: 0.0208 - accuracy: 0.0731 - val_loss: 0.0191 - val_accuracy: 0.0802 - lr: 0.0010\n",
      "Epoch 7/25\n",
      "149/149 [==============================] - 19s 130ms/step - loss: 0.0202 - accuracy: 0.0790 - val_loss: 0.0187 - val_accuracy: 0.0806 - lr: 0.0010\n",
      "Epoch 8/25\n",
      "149/149 [==============================] - 19s 130ms/step - loss: 0.0193 - accuracy: 0.0866 - val_loss: 0.0182 - val_accuracy: 0.0859 - lr: 0.0010\n",
      "Epoch 9/25\n",
      "149/149 [==============================] - 21s 140ms/step - loss: 0.0189 - accuracy: 0.0911 - val_loss: 0.0178 - val_accuracy: 0.1172 - lr: 0.0010\n",
      "Epoch 10/25\n",
      "149/149 [==============================] - 21s 140ms/step - loss: 0.0187 - accuracy: 0.0986 - val_loss: 0.0176 - val_accuracy: 0.0976 - lr: 0.0010\n",
      "Epoch 11/25\n",
      "149/149 [==============================] - 20s 133ms/step - loss: 0.0183 - accuracy: 0.1035 - val_loss: 0.0175 - val_accuracy: 0.1105 - lr: 0.0010\n",
      "Epoch 12/25\n",
      "149/149 [==============================] - 21s 139ms/step - loss: 0.0179 - accuracy: 0.1048 - val_loss: 0.0171 - val_accuracy: 0.0991 - lr: 0.0010\n",
      "Epoch 13/25\n",
      "149/149 [==============================] - 22s 144ms/step - loss: 0.0175 - accuracy: 0.1099 - val_loss: 0.0171 - val_accuracy: 0.1002 - lr: 0.0010\n",
      "Epoch 14/25\n",
      "149/149 [==============================] - 22s 149ms/step - loss: 0.0171 - accuracy: 0.1141 - val_loss: 0.0166 - val_accuracy: 0.1207 - lr: 0.0010\n",
      "Epoch 15/25\n",
      "149/149 [==============================] - 26s 177ms/step - loss: 0.0171 - accuracy: 0.1149 - val_loss: 0.0167 - val_accuracy: 0.1165 - lr: 0.0010\n",
      "Epoch 16/25\n",
      "149/149 [==============================] - 22s 148ms/step - loss: 0.0165 - accuracy: 0.1216 - val_loss: 0.0164 - val_accuracy: 0.1073 - lr: 0.0010\n",
      "Epoch 17/25\n",
      "149/149 [==============================] - 29s 194ms/step - loss: 0.0162 - accuracy: 0.1240 - val_loss: 0.0162 - val_accuracy: 0.1063 - lr: 0.0010\n",
      "Epoch 18/25\n",
      "149/149 [==============================] - 26s 177ms/step - loss: 0.0161 - accuracy: 0.1306 - val_loss: 0.0164 - val_accuracy: 0.1113 - lr: 0.0010\n",
      "Epoch 19/25\n",
      "149/149 [==============================] - 25s 171ms/step - loss: 0.0158 - accuracy: 0.1371 - val_loss: 0.0162 - val_accuracy: 0.1121 - lr: 0.0010\n",
      "Epoch 20/25\n",
      "149/149 [==============================] - 28s 187ms/step - loss: 0.0154 - accuracy: 0.1418 - val_loss: 0.0160 - val_accuracy: 0.1161 - lr: 0.0010\n",
      "Epoch 21/25\n",
      "149/149 [==============================] - 26s 172ms/step - loss: 0.0151 - accuracy: 0.1470 - val_loss: 0.0162 - val_accuracy: 0.1273 - lr: 0.0010\n",
      "Epoch 22/25\n",
      "149/149 [==============================] - 28s 187ms/step - loss: 0.0147 - accuracy: 0.1559 - val_loss: 0.0159 - val_accuracy: 0.1249 - lr: 0.0010\n",
      "Epoch 23/25\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.0143 - accuracy: 0.1662\n",
      "Epoch 00023: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "149/149 [==============================] - 29s 197ms/step - loss: 0.0143 - accuracy: 0.1662 - val_loss: 0.0160 - val_accuracy: 0.1212 - lr: 0.0010\n",
      "Epoch 24/25\n",
      "149/149 [==============================] - 26s 174ms/step - loss: 0.0137 - accuracy: 0.1768 - val_loss: 0.0158 - val_accuracy: 0.1222 - lr: 1.0000e-04\n",
      "Epoch 25/25\n",
      "149/149 [==============================] - 30s 202ms/step - loss: 0.0135 - accuracy: 0.1840 - val_loss: 0.0157 - val_accuracy: 0.1231 - lr: 1.0000e-04\n",
      "\n"
     ]
    }
   ],
   "source": [
    "N_STARTS = 2\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "res = data_train_target_s.copy()\n",
    "sub.loc[:, data_train_target_s.columns] = 0\n",
    "sub.loc[:, data_train_target_s.columns] = 0\n",
    "\n",
    "for seed in range(N_STARTS):\n",
    "    for n, (train_idx, test_idx) in enumerate(KFold(n_splits=5, random_state=seed, shuffle=True).split(data_train_target_s, data_train_target_s)):\n",
    "        print(f'Fold {n}')\n",
    "    \n",
    "        model = create_model(875)\n",
    "        checkpoint_path = f'repeat:{seed}_Fold:{n}.h5'\n",
    "        reduce_lr_loss = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=3, verbose=1, epsilon=1e-4, mode='min')\n",
    "        cb_checkpt = ModelCheckpoint(checkpoint_path, monitor = 'val_loss', verbose = 0, save_best_only = True,\n",
    "                                     save_weights_only = True, mode = 'min')\n",
    "        model.fit(train.values[train_idx],\n",
    "                  data_train_target_s.values[train_idx],\n",
    "                  validation_data=(train.values[test_idx], data_train_target_s.values[test_idx]),\n",
    "                  epochs=25, batch_size=128,\n",
    "                  callbacks=[reduce_lr_loss, cb_checkpt], verbose=1\n",
    "                 )\n",
    "        \n",
    "        model.load_weights(checkpoint_path)\n",
    "        test_predict = model.predict(test.values)\n",
    "        val_predict = model.predict(train.values[test_idx])\n",
    "        \n",
    "        sub.loc[:, data_train_target_s.columns] += test_predict\n",
    "        res.loc[test_idx, data_train_target_s.columns] += val_predict\n",
    "        print('')\n",
    "    \n",
    "sub.loc[:, data_train_target_s.columns] /= ((n+1) * N_STARTS)\n",
    "res.loc[:, data_train_target_s.columns] /= N_STARTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "7p0Q-wdQ7qz5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OOF Metric: 0.0037305020626018834\n"
     ]
    }
   ],
   "source": [
    "print(f'OOF Metric: {metric(data_train_target_s, res)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "7TFnWagM7s2F"
   },
   "outputs": [],
   "source": [
    "sub.loc[test['cp_type']==1, data_train_target_s.columns] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "YCkhXwhk7tO7"
   },
   "outputs": [],
   "source": [
    "sub.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "Project Update.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
